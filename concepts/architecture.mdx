---
title: System architecture
description: Understanding Reze's technical architecture and component integration
---

## Overview

Reze is built on a modern Python stack that combines FastAPI for the web layer, PydanticAI for agent orchestration, GLM 4.7 for language processing, and Memvid for knowledge retrieval. The system uses SQLite for conversation persistence and integrates with Resend.com for email operations.

## Core components

### FastAPI application layer

The application uses FastAPI with async lifespan management to handle startup and shutdown events:

```python src/api/app.py
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan manager.
    
    Handles startup and shutdown events for FastAPI application.
    """
    logger.info("Starting Reze AI Agent application...")
    
    try:
        logger.info("Initializing database schema...")
        await init_db()
        logger.info("Database schema initialized successfully")
    except Exception as e:
        logger.error(f"Failed to initialize database schema: {e}")
    
    try:
        logger.info("Initializing Memvid service...")
        stats = memvid_service.get_stats()
        logger.info(f"Memvid service initialized: {stats}")
    except Exception as e:
        logger.error(f"Failed to initialize Memvid service: {e}")
    
    yield
    logger.info("Shutting down Reze AI Agent application...")
```

<Note>
The lifespan manager ensures that both the database and Memvid service are properly initialized before the application starts accepting requests.
</Note>

### PydanticAI agent

Reze uses PydanticAI as the orchestration layer, connecting to GLM 4.7 via OpenAI-compatible protocol:

```python src/services/ai.py
def _create_agent(self) -> Agent:
    """Create GLM 4.7 agent with OpenAI-compatible protocol.
    
    Returns:
        Configured Agent instance
    """
    provider = OpenAIProvider(
        api_key=settings.glm_api_key,
        base_url=settings.glm_base_url,
    )
    
    model = OpenAIChatModel(
        model_name=settings.glm_model,
        provider=provider,
    )
    
    return Agent(
        model,
        tools=ALL_TOOLS,
        name="reze_agent",
        system_prompt=[REZE_PERSONA, REZE_INSTRUCTIONS],
    )
```

### GLM 4.7 language model

GLM 4.7 from z.ai serves as the core language model, accessed through an OpenAI-compatible endpoint:

```python src/config.py
glm_api_key: str = Field(
    default="test_glm_key",
    env="GLM_API_KEY",
    description="GLM 4.7 API key from z.ai",
)
glm_base_url: str = Field(
    default="https://open.bigmodel.cn/api/paas/v4",
    env="GLM_BASE_URL",
    description="GLM 4.7 base URL (OpenAI-compatible)",
)
glm_model: str = Field(
    default="glm-4.7",
    env="GLM_MODEL",
    description="GLM model name",
)
```

<Info>
The OpenAI-compatible interface allows seamless integration with PydanticAI's OpenAIChatModel, making it easy to swap models if needed.
</Info>

### Memvid RAG system

Memvid provides a single-file knowledge base with hybrid search capabilities (BM25 + semantic vectors):

```python src/services/memvid.py
self.mem = use(
    kind=settings.memvid_index_kind,
    filename=self.memvid_path,
    enable_lex=True,
    enable_vec=False,
    mode="open",
)
```

The service includes automatic backup and recovery mechanisms to handle corruption:

```python src/services/memvid.py
def _create_backup(self) -> None:
    """Create a backup of Memvid file."""
    try:
        if os.path.exists(self.memvid_path):
            shutil.copy2(self.memvid_path, self.backup_path)
            logger.debug(f"Created backup at: {self.backup_path}")
    except Exception as e:
        logger.warning(f"Failed to create backup: {e}")
```

### Resend API integration

The system integrates with Resend.com for email operations through PydanticAI tools:

```python src/tools/resend.py
async def send_email(ctx: RunContext, data: SendEmailRequest) -> str:
    """Send an email via Resend.com API."""
    try:
        result = await resend_service.send_email(data)
        
        return f"✓ Email sent successfully! Email ID: {result.id}. It should be delivered shortly. Would you like me to check its delivery status?"
    except Exception as e:
        return f"✗ Failed to send email: {str(e)}. Please check the email address and try again."
```

<Tip>
All tools return user-friendly messages with emoji indicators (✓, ✗, ⚠️) to make responses more readable in chat interfaces.
</Tip>

### SQLite conversation storage

Conversations are persisted in SQLite using async SQLAlchemy:

```python src/config.py
database_url: str = Field(
    default="sqlite+aiosqlite:///./database",
    env="DATABASE_URL",
    description="SQLAlchemy database URL",
)
```

Each conversation is identified by a UUID and stores messages with timestamps and roles:

```python src/services/conversation.py
async def add_message(
    self,
    conversation_id: str,
    role: str,
    content: str,
    username: str = "anonymous",
) -> None:
    """Add a message to conversation history."""
    async with async_session_maker() as db_session:
        message = ConversationLog(
            conversation_id=conversation_id,
            role=role,
            content=content,
            username=username,
        )
        db_session.add(message)
        await db_session.commit()
        await db_session.refresh(message)
```

## Component interaction flow

1. **Request handling**: FastAPI receives chat requests and routes them to appropriate handlers
2. **Context retrieval**: RAG service queries Memvid for relevant documentation
3. **Agent processing**: PydanticAI agent processes the user message with GLM 4.7
4. **Tool execution**: Agent calls Resend API tools when email operations are needed
5. **Response storage**: Conversation service persists messages to SQLite
6. **Response delivery**: FastAPI streams or returns the final response to the client

## Configuration management

All components are configured through environment variables using Pydantic Settings:

```python src/config.py
class Settings(BaseSettings):
    """Main settings container with flat structure for .env reading."""
    
    # Application Settings
    debug: bool = Field(default=True, env="DEBUG")
    host: str = Field(default="0.0.0.0", env="HOST")
    port: int = Field(default=8000, env="PORT")
    
    # GLM 4.7 AI Provider Settings
    glm_api_key: str = Field(default="test_glm_key", env="GLM_API_KEY")
    glm_base_url: str = Field(
        default="https://open.bigmodel.cn/api/paas/v4",
        env="GLM_BASE_URL",
    )
    
    # Resend.com API Settings
    resend_api_key: str = Field(default="re_test_key", env="RESEND_API_KEY")
    resend_from_email: EmailStr = Field(
        default="test@example.com",
        env="RESEND_FROM_EMAIL",
    )
    
    # Memvid RAG Settings
    memvid_file_path: str = Field(
        default="./memory.mv2",
        env="MEMVID_FILE_PATH",
    )
    memvid_index_kind: Literal["basic", "advanced"] = Field(
        default="basic",
        env="MEMVID_INDEX_KIND",
    )
```

<Note>
All configuration values have sensible defaults but should be overridden in production environments through `.env` files.
</Note>
